{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4c9121-4a19-4f48-83e2-85f6982d48d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:25:30.593718Z",
     "iopub.status.busy": "2024-03-20T08:25:30.593718Z",
     "iopub.status.idle": "2024-03-20T08:25:31.713753Z",
     "shell.execute_reply": "2024-03-20T08:25:31.713753Z",
     "shell.execute_reply.started": "2024-03-20T08:25:30.593718Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbe1d2-d272-4e02-bfd4-581ecdcf53a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2a3e40-f3c0-4621-ac15-0c0087b032d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:25:15.414940Z",
     "iopub.status.busy": "2024-03-20T08:25:15.414940Z",
     "iopub.status.idle": "2024-03-20T08:25:15.419891Z",
     "shell.execute_reply": "2024-03-20T08:25:15.419891Z",
     "shell.execute_reply.started": "2024-03-20T08:25:15.414940Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL: y = wx + b\n",
    "# PARAMETERS: w, b\n",
    "# MODEL: f()\n",
    "# COST FUNCTION: j()\n",
    "\n",
    "# w and b are called collectively called as coefficients or separately as weights and biases.\n",
    "# we need to find the best possible values for w and b, such that our estimates end upas close as possible to the real targets.\n",
    "# what the cost function does is that it measures the difference between the model's predictions and the true target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3130103-7cec-4721-a786-e9b99840a549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554ced95-e8eb-4c34-8791-39296ad7f991",
   "metadata": {},
   "source": [
    "# ___$j(w, b) = \\frac{1}{2N}\\sum_{i = 0}^{N}(f(x_i) - y_i)^2$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482e3a2-c501-455a-9f59-d99e5cc867df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19baeb41-03af-4a7b-a986-5268214ed0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:25:15.523587Z",
     "iopub.status.busy": "2024-03-20T08:25:15.523587Z",
     "iopub.status.idle": "2024-03-20T08:25:15.531039Z",
     "shell.execute_reply": "2024-03-20T08:25:15.531039Z",
     "shell.execute_reply.started": "2024-03-20T08:25:15.523587Z"
    }
   },
   "outputs": [],
   "source": [
    "# f(x_i) = is the prediction for the ith record (y_hat_i)\n",
    "# f(x_i) - y_i = gives the difference between the prediction and the actual y value.\n",
    "# (f(x_i) - y_i)^2 gives us the squared error, which will cancel out signs\n",
    "\n",
    "# for this reason, this cost function is also called the squared error cost function.\n",
    "# there are a plethora of cost functions available to use with linear regression models but squared error cost functions are by far the most common\n",
    "# type of cost functions used in linera regression.\n",
    "\n",
    "# cost function gives us the half of the average of squares of such differences across all N records.\n",
    "# our goal is to make j(w, b) as small as possible, i.e bring the predictions and targets as close as possible :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434b516-d7d9-4000-8c94-4dc6efbbff17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f49f8dd-0021-4329-bc7d-67d477d73cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:25:59.907386Z",
     "iopub.status.busy": "2024-03-20T08:25:59.907386Z",
     "iopub.status.idle": "2024-03-20T08:25:59.952412Z",
     "shell.execute_reply": "2024-03-20T08:25:59.952412Z",
     "shell.execute_reply.started": "2024-03-20T08:25:59.907386Z"
    }
   },
   "outputs": [],
   "source": [
    "beans = pd.read_csv(r\"../anoban/Dry_Bean_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e38835-8015-4391-9d0c-42432908fe13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:26:00.348787Z",
     "iopub.status.busy": "2024-03-20T08:26:00.348787Z",
     "iopub.status.idle": "2024-03-20T08:26:00.352538Z",
     "shell.execute_reply": "2024-03-20T08:26:00.352538Z",
     "shell.execute_reply.started": "2024-03-20T08:26:00.348787Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature and target\n",
    "\n",
    "x = beans.MajorAxisLength.to_numpy()\n",
    "y = beans.Area.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4eca2d-b4d8-4728-9098-8946a2480f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9309203a-0d0e-41b3-9b3a-041559b69c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:26:01.149985Z",
     "iopub.status.busy": "2024-03-20T08:26:01.149985Z",
     "iopub.status.idle": "2024-03-20T08:26:01.155005Z",
     "shell.execute_reply": "2024-03-20T08:26:01.155005Z",
     "shell.execute_reply.started": "2024-03-20T08:26:01.149985Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's think of an oversimplified version of the model, \n",
    "# say that we do not have an intercept (bias) term in the model and the model could simply be defined in the form of x = mx\n",
    "# now we only need to find the gradient (slope or weigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6705f6c-9c22-441f-a565-bf314e1b2d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88266ade-0b4f-41ca-a408-f8800b3c405c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T08:42:19.600014Z",
     "iopub.status.busy": "2024-03-20T08:42:19.600014Z",
     "iopub.status.idle": "2024-03-20T08:42:19.606167Z",
     "shell.execute_reply": "2024-03-20T08:42:19.606167Z",
     "shell.execute_reply.started": "2024-03-20T08:42:19.600014Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's handroll a linear regression model\n",
    "\n",
    "@jit(nopython = True, parallel = False, fastmath = True)\n",
    "def gradient_descent(predictions: NDArray[np.float64], targets: NDArray[np.float64]) -> np.float64:\n",
    "    \"\"\"\n",
    "    computes the average of squared differences between the actual targets and predictions.\n",
    "    and returns the half of the mean squared difference.\n",
    "    \"\"\"\n",
    "    assertpredictions.size == targets.size,\n",
    "    f\"Both predictions and targets must have the same size! but received targets::{targets.size:10,d}, predictions::{predictions.size:10,d}\"\n",
    "    return np.square(predictions - targets).sum() / (2 * targets.size)\n",
    "\n",
    "\n",
    "@jit(nopython = True, parallel = False, fastmath = True)\n",
    "def linear_regression(predictor: NDArray[np.float64], targets: NDArray[np.float64], learning_rate: float = 0.1, epsilon: float = 10.0) -> np.float64:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    error_margin: float = 100.0000\n",
    "    slope: float = (targets - predictor).mean()\n",
    "\n",
    "    while(error_margin >= epsilon):\n",
    "        error_margin = np.square((slope * predictor) - targets).sum() / (2 * predictor.size)\n",
    "        slope += learning_rate\n",
    "    return slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45036e54-0048-4cb9-a3a4-15e4ce90908b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be01e59-aa3f-4fd8-b57d-8276594e0acc",
   "metadata": {
    "execution": {
     "execution_failed": "2024-03-20T08:25:25.400Z"
    }
   },
   "outputs": [],
   "source": [
    "# for our bias less model,\n",
    "# y_hat = f(x) = wx\n",
    "# as we do not need a bias term, we only have one parameter - w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d08069-4264-4267-86ff-766f781388ce",
   "metadata": {},
   "source": [
    "# ___$j(w) = \\frac{1}{2N}\\sum_{i=0}^{N}(f(x_i) - y_i)^2$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97df6f-4076-4e0d-bf7f-40a67a6b3232",
   "metadata": {
    "execution": {
     "execution_failed": "2024-03-20T08:25:25.401Z"
    }
   },
   "outputs": [],
   "source": [
    "# which becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74d63b-a3e6-44e3-ac65-5c6a8d4d8b14",
   "metadata": {},
   "source": [
    "# ___$j(w) = \\frac{1}{2N}\\sum_{i=0}^{N}(w \\cdot x_i - y_i)^2$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811373c-2f9a-4eee-ab63-71f9a6a1d0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
