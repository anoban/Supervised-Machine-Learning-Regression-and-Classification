{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f6213c-185b-49da-a65b-be823e118e1d",
   "metadata": {},
   "source": [
    "# ___Gradient Descent For Multiple Linear Regression___\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46d0193-baa7-4d0c-bf8f-d287841453ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T13:19:18.668660Z",
     "iopub.status.busy": "2024-04-18T13:19:18.668660Z",
     "iopub.status.idle": "2024-04-18T13:19:19.874456Z",
     "shell.execute_reply": "2024-04-18T13:19:19.874456Z",
     "shell.execute_reply.started": "2024-04-18T13:19:18.668660Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b4fdb-f99c-4147-b68b-eb69795d561b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88067034-9444-40ef-ad65-1732f0f535ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693cab4-212a-49e4-938a-c04620c6c174",
   "metadata": {},
   "source": [
    "### ___$= [w_1~~w_2~~w_3 \\cdots w_n], b ~~\\text{alternatively,}~~ = \\overrightarrow{w}, b$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd0ec1-ccdc-4a49-b659-ae973ef4534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4185ad-c3f5-4eee-b35b-ec8114e25772",
   "metadata": {},
   "source": [
    "### ___$= f_{w,b}(x) = w_1x_1 + w_2x_2 + w_3x_3 \\cdots + w_nx_n + b ~~\\text{alternatively,}~~ f_{w,b}(x) = \\overrightarrow{x} \\cdot \\overrightarrow{w} + b$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650c62d-b941-440a-bffa-338fd0747e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3d29d-b87e-4d36-8379-4f53627422df",
   "metadata": {},
   "source": [
    "### ___$= j(w_1, w_2, w_3 \\cdots b) ~~\\text{alternatively,}~~ = j(\\overrightarrow{w}, b)$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4840444-697b-4ee5-a064-d539d147d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c90a08f-587d-4515-a260-7b575b104a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T13:21:54.660582Z",
     "iopub.status.busy": "2024-04-18T13:21:54.660582Z",
     "iopub.status.idle": "2024-04-18T13:21:54.673502Z",
     "shell.execute_reply": "2024-04-18T13:21:54.673432Z",
     "shell.execute_reply.started": "2024-04-18T13:21:54.660582Z"
    }
   },
   "outputs": [],
   "source": [
    "# how does a least squares cost function operate on a multiple predictor dataset?\n",
    "# N - number of records in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7542b7-ebdb-4252-8d98-c0d118438d38",
   "metadata": {},
   "source": [
    "## ___Univariate $\\Rightarrow$___\n",
    "## ___$j(w, b) = \\frac{1}{2N}\\sum_{i=0}^{N}(f_{w,b}(x_i) - y_i)^2$___\n",
    "## ___$j(w, b) = \\frac{1}{2N}\\sum_{i=0}^{N}(w_ix_i + b - y_i)^2$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed99a8-5fa7-4dac-a534-e511620da103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed949d9c-3274-4a25-9e13-26799d27c54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T22:03:39.154998Z",
     "iopub.status.busy": "2024-05-04T22:03:39.154998Z",
     "iopub.status.idle": "2024-05-04T22:03:39.164273Z",
     "shell.execute_reply": "2024-05-04T22:03:39.163442Z",
     "shell.execute_reply.started": "2024-05-04T22:03:39.154998Z"
    }
   },
   "source": [
    "## ___Multiple variables $\\Rightarrow$___\n",
    "## ___$j(\\overrightarrow{w}, b) = \\frac{1}{2N}\\sum_{i=0}^{N}(f_{w,b}(\\overrightarrow{x_i}) - y_i)^2$___\n",
    "## ___$j(\\overrightarrow{w}, b) = \\frac{1}{2N}\\sum_{i=0}^{N}(\\overrightarrow{w_i} \\cdot \\overrightarrow{x_i} + b - y_i)^2$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b92fb3-d2fa-4546-b033-560b10d39f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple linear regression, we'll have separate partial derivatives of cost functions for each predictor, computing how the prediction deviates\n",
    "# from the actual value with changes in the select predictor (hence the use of partial derivatives!)\n",
    "# for a dataset with n predictors, we'll have cost functions 0 through n, corresponding to each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f81b1ef-fdc6-4f10-9dbf-a23ac3ceb6d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T13:43:19.540960Z",
     "iopub.status.busy": "2024-04-18T13:43:19.540960Z",
     "iopub.status.idle": "2024-04-18T13:43:19.556957Z",
     "shell.execute_reply": "2024-04-18T13:43:19.556957Z",
     "shell.execute_reply.started": "2024-04-18T13:43:19.540960Z"
    }
   },
   "outputs": [],
   "source": [
    "# here's what the gradient descent looks like,\n",
    "# repeat until convergence [W_I DENOTES THE COEFFICIENT OF THE ITH VARIABLE OR PREDICTOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae672d4-6b6a-4ac8-965a-6f77aeed0f7a",
   "metadata": {},
   "source": [
    "## ___$w_i = w_i - \\alpha \\cdot \\frac{\\partial{j(\\overrightarrow{w}, b)}}{\\partial{w_i}}$___\n",
    "## ___$b = b - \\alpha \\cdot \\frac{\\partial{j(\\overrightarrow{w}, b)}}{\\partial{b}}$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784273c-c38c-40b0-b724-c0075a4efde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be0b28a1-2678-4484-8b3d-9f2b21d2cfd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T05:54:20.502094Z",
     "iopub.status.busy": "2024-04-18T05:54:20.502094Z",
     "iopub.status.idle": "2024-04-18T05:54:20.518195Z",
     "shell.execute_reply": "2024-04-18T05:54:20.518195Z",
     "shell.execute_reply.started": "2024-04-18T05:54:20.502094Z"
    }
   },
   "source": [
    "## ___HERE'S A DEEP DIVE INTO THE WEIGHTS UPATE___\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073e9ddf-e1e5-41bb-8cef-2e7f789b22fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T05:56:01.885757Z",
     "iopub.status.busy": "2024-04-18T05:56:01.885757Z",
     "iopub.status.idle": "2024-04-18T05:56:01.901905Z",
     "shell.execute_reply": "2024-04-18T05:56:01.901905Z",
     "shell.execute_reply.started": "2024-04-18T05:56:01.885757Z"
    }
   },
   "outputs": [],
   "source": [
    "# for univariate linear regression, we had the following rules to get the derivative of the cost function with respect to w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8368dd-c3ec-4aa8-bdd8-2fa349d6a721",
   "metadata": {},
   "source": [
    "## ___$ \\frac{\\partial}{\\partial{w}}j(w, b) = \\frac{\\partial}{\\partial{w}} \\frac{1}{2N} \\sum_{i=0}^{N} (f_{w, b}(x_i) - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{\\partial}{\\partial{w}} \\frac{1}{2N} \\sum_{i=0}^{N} (w_ix_i + b - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{1}{N} \\sum_{i=0}^{N} (w_ix_i + b - y_i) \\times x_i$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea61d97-e4ac-4904-a53c-aa3252395b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ceef9ef-ae64-4558-b30e-80a862464664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T22:33:16.279021Z",
     "iopub.status.busy": "2024-05-04T22:33:16.279021Z",
     "iopub.status.idle": "2024-05-04T22:33:16.284638Z",
     "shell.execute_reply": "2024-05-04T22:33:16.284569Z",
     "shell.execute_reply.started": "2024-05-04T22:33:16.279021Z"
    }
   },
   "outputs": [],
   "source": [
    "# for multiple linear regression,\n",
    "# REMEMBER Y AND B ARE ALWAYS SCALARS!\n",
    "# we cannot compute the derivative of the cost function with respect to the vector of weights\n",
    "# DERIVATIVE OF THE COST FUNCTION WITH RESPECT TO EACH WEIGHT MUST BE COMPUTED INDIVIDUALLY AS PARTIAL DERIVATIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff1f59-5630-4c41-bbdf-0fc31c7c4de3",
   "metadata": {},
   "source": [
    "## ___$\\frac{\\partial}{\\partial{w_1}}j(\\overrightarrow{w}, b) = \\frac{\\partial}{\\partial{w_1}} \\frac{1}{2N} \\sum_{i=0}^{N} (f_{w, b}(\\overrightarrow{x_i}) - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{\\partial}{\\partial{w_1}} \\frac{1}{2N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{1}{N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i) \\times x_{1i}$___\n",
    "\n",
    "## ___$~~~~~~~~~~~~~~~~~~~~\\vdots$___\n",
    "\n",
    "## ___$\\frac{\\partial}{\\partial{w_n}}j(\\overrightarrow{w}, b) = \\frac{\\partial}{\\partial{w_n}} \\frac{1}{2N} \\sum_{i=0}^{N} (f_{w, b}(\\overrightarrow{x_i}) - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{\\partial}{\\partial{w_n}} \\frac{1}{2N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{1}{N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i) \\times x_{ni}$___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9927840-555a-4efb-ae01-c4a580e40d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T14:29:03.922798Z",
     "iopub.status.busy": "2024-04-18T14:29:03.922798Z",
     "iopub.status.idle": "2024-04-18T14:29:03.938793Z",
     "shell.execute_reply": "2024-04-18T14:29:03.938250Z",
     "shell.execute_reply.started": "2024-04-18T14:29:03.922798Z"
    }
   },
   "outputs": [],
   "source": [
    "# for a dataset with n predictors, we need to repeat this for all n weights!\n",
    "# NOTE THAT THE X RESULTING FROM THE DERIVATION REPRESENTS THE X VALUE FOR THE SELECTED WEIGHT i.e the first predictor, NOT THE WHOLE ROW VECTOR!\n",
    "# IT IS A SCALAR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35811ffa-cc8b-4f83-b730-dd7cd6b4c252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5210311b-d666-4d42-a82d-bd3e9d48c00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T14:30:19.323952Z",
     "iopub.status.busy": "2024-04-18T14:30:19.323952Z",
     "iopub.status.idle": "2024-04-18T14:30:19.342099Z",
     "shell.execute_reply": "2024-04-18T14:30:19.341974Z",
     "shell.execute_reply.started": "2024-04-18T14:30:19.323952Z"
    }
   },
   "outputs": [],
   "source": [
    "# for the bias term in univariate linear regression,\n",
    "# the derivative of the cost function with respect to the bias term is,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639daa32-28f9-4510-b3af-a0419e33a3a2",
   "metadata": {},
   "source": [
    "## ___$ \\frac{\\partial}{\\partial{b}}j(w, b) = \\frac{\\partial}{\\partial{b}} \\frac{1}{2N} \\sum_{i=0}^{N} (f_{w, b}(x_i) - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{\\partial}{\\partial{w}} \\frac{1}{2N} \\sum_{i=0}^{N} (w_ix_i + b - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{1}{N} \\sum_{i=0}^{N} (w_ix_i + b - y_i)$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f71ae4-9685-4cae-94fb-c4e085411fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T14:32:45.224973Z",
     "iopub.status.busy": "2024-04-18T14:32:45.224973Z",
     "iopub.status.idle": "2024-04-18T14:32:45.235274Z",
     "shell.execute_reply": "2024-04-18T14:32:45.235274Z",
     "shell.execute_reply.started": "2024-04-18T14:32:45.224973Z"
    }
   },
   "outputs": [],
   "source": [
    "# good thing, even in multiple linear regression, we have only one bias term!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e4151-bf7b-43ae-a04d-2cb42db8f7c2",
   "metadata": {},
   "source": [
    "## ___$\\frac{\\partial}{\\partial{b}}j(\\overrightarrow{w}, b) = \\frac{\\partial}{\\partial{b}} \\frac{1}{2N} \\sum_{i=0}^{N} (f_{w, b}(\\overrightarrow{x_i}) - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{\\partial}{\\partial{b}} \\frac{1}{2N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i)^2$___\n",
    "## ___$~~~~~~~~~~~~~~~~~= \\frac{1}{N} \\sum_{i=0}^{N} (\\overrightarrow{w_i}\\cdot\\overrightarrow{x_i} + b - y_i)$___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f063033-2323-44be-9129-17f22e72adef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb155ac-825d-498f-b6f8-f362653b4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN GRADIENT DESCENT THESE PARTIAL DERIVATIVES NEED TO BE MULTIPLIED BY THE ALPHA AND SUBTRACTED FROM THE INITIAL COGNATE PARAMETERS\n",
    "# I.E SIMULTANEOUS UPDATE OF EACH WEIGHT AND THE THE BIAS TERM!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
